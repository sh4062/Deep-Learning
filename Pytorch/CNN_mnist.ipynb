{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_dim, n_class):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(in_dim,6,3,stride=1,padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(6,16,5,stride=1,padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d((2,2)))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(400, 120), nn.Linear(120, 84), nn.Linear(84, n_class))\n",
    "    def forward(self,x):\n",
    "            out = self.conv(x)\n",
    "            out = out.view(out.size(0),-1)\n",
    "            out = self.fc(out)\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(1, 10)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1\n",
      "**********\n",
      "[1/20] Loss: 2.294286, Acc: 0.139974\n",
      "Finish 1 epoch, Loss: 2.278495, Acc: 0.228983\n",
      "Test Loss: 2.201852, Acc: 0.402400\n",
      "\n",
      "epoch2\n",
      "**********\n",
      "[2/20] Loss: 1.561980, Acc: 0.617656\n",
      "Finish 2 epoch, Loss: 1.197886, Acc: 0.698133\n",
      "Test Loss: 0.446033, Acc: 0.869100\n",
      "\n",
      "epoch3\n",
      "**********\n",
      "[3/20] Loss: 0.407683, Acc: 0.878255\n",
      "Finish 3 epoch, Loss: 0.377899, Acc: 0.886617\n",
      "Test Loss: 0.303780, Acc: 0.909100\n",
      "\n",
      "epoch4\n",
      "**********\n",
      "[4/20] Loss: 0.294032, Acc: 0.911120\n",
      "Finish 4 epoch, Loss: 0.285762, Acc: 0.913967\n",
      "Test Loss: 0.231965, Acc: 0.930200\n",
      "\n",
      "epoch5\n",
      "**********\n",
      "[5/20] Loss: 0.241058, Acc: 0.927552\n",
      "Finish 5 epoch, Loss: 0.233191, Acc: 0.929550\n",
      "Test Loss: 0.200574, Acc: 0.940500\n",
      "\n",
      "epoch6\n",
      "**********\n",
      "[6/20] Loss: 0.203748, Acc: 0.938281\n",
      "Finish 6 epoch, Loss: 0.195470, Acc: 0.941517\n",
      "Test Loss: 0.162385, Acc: 0.949400\n",
      "\n",
      "epoch7\n",
      "**********\n",
      "[7/20] Loss: 0.172776, Acc: 0.947187\n",
      "Finish 7 epoch, Loss: 0.166857, Acc: 0.949367\n",
      "Test Loss: 0.139206, Acc: 0.958000\n",
      "\n",
      "epoch8\n",
      "**********\n",
      "[8/20] Loss: 0.148768, Acc: 0.954766\n",
      "Finish 8 epoch, Loss: 0.145887, Acc: 0.955833\n",
      "Test Loss: 0.127073, Acc: 0.960500\n",
      "\n",
      "epoch9\n",
      "**********\n",
      "[9/20] Loss: 0.131281, Acc: 0.961250\n",
      "Finish 9 epoch, Loss: 0.129979, Acc: 0.960667\n",
      "Test Loss: 0.109678, Acc: 0.966700\n",
      "\n",
      "epoch10\n",
      "**********\n",
      "[10/20] Loss: 0.116397, Acc: 0.965443\n",
      "Finish 10 epoch, Loss: 0.118083, Acc: 0.964550\n",
      "Test Loss: 0.097243, Acc: 0.970300\n",
      "\n",
      "epoch11\n",
      "**********\n",
      "[11/20] Loss: 0.108665, Acc: 0.967682\n",
      "Finish 11 epoch, Loss: 0.108543, Acc: 0.967117\n",
      "Test Loss: 0.095627, Acc: 0.971000\n",
      "\n",
      "epoch12\n",
      "**********\n",
      "[12/20] Loss: 0.102826, Acc: 0.969245\n",
      "Finish 12 epoch, Loss: 0.101355, Acc: 0.969333\n",
      "Test Loss: 0.085737, Acc: 0.972300\n",
      "\n",
      "epoch13\n",
      "**********\n",
      "[13/20] Loss: 0.094860, Acc: 0.970833\n",
      "Finish 13 epoch, Loss: 0.094892, Acc: 0.971267\n",
      "Test Loss: 0.082427, Acc: 0.972700\n",
      "\n",
      "epoch14\n",
      "**********\n",
      "[14/20] Loss: 0.088617, Acc: 0.973698\n",
      "Finish 14 epoch, Loss: 0.089456, Acc: 0.972933\n",
      "Test Loss: 0.078008, Acc: 0.974100\n",
      "\n",
      "epoch15\n",
      "**********\n",
      "[15/20] Loss: 0.086500, Acc: 0.974036\n",
      "Finish 15 epoch, Loss: 0.085423, Acc: 0.974067\n",
      "Test Loss: 0.077695, Acc: 0.974900\n",
      "\n",
      "epoch16\n",
      "**********\n",
      "[16/20] Loss: 0.079889, Acc: 0.976042\n",
      "Finish 16 epoch, Loss: 0.081531, Acc: 0.975067\n",
      "Test Loss: 0.070364, Acc: 0.977600\n",
      "\n",
      "epoch17\n",
      "**********\n",
      "[17/20] Loss: 0.079064, Acc: 0.976380\n",
      "Finish 17 epoch, Loss: 0.077572, Acc: 0.976733\n",
      "Test Loss: 0.069420, Acc: 0.979200\n",
      "\n",
      "epoch18\n",
      "**********\n",
      "[18/20] Loss: 0.075096, Acc: 0.977396\n",
      "Finish 18 epoch, Loss: 0.074461, Acc: 0.977267\n",
      "Test Loss: 0.063851, Acc: 0.979700\n",
      "\n",
      "epoch19\n",
      "**********\n",
      "[19/20] Loss: 0.072026, Acc: 0.978203\n",
      "Finish 19 epoch, Loss: 0.071858, Acc: 0.978183\n",
      "Test Loss: 0.066950, Acc: 0.977000\n",
      "\n",
      "epoch20\n",
      "**********\n",
      "[20/20] Loss: 0.066433, Acc: 0.979557\n",
      "Finish 20 epoch, Loss: 0.069192, Acc: 0.978667\n",
      "Test Loss: 0.062722, Acc: 0.980500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epoches):\n",
    "    print('epoch{}'.format(epoch+1))\n",
    "    print('*'*10)\n",
    "    running_loss=0.0\n",
    "    running_acc=0.0\n",
    "    for i,data in enumerate(train_loader,1):\n",
    "        img,label=data\n",
    "        img = img.cuda()\n",
    "        label = label.cuda()\n",
    "        img = Variable(img)\n",
    "        label = Variable(label)\n",
    "        #forward\n",
    "        out=model(img)\n",
    "        loss=criterion(out,label)\n",
    "        running_loss+=loss.data[0]*label.size(0)\n",
    "        _,pred=torch.max(out,1)\n",
    "        num_correct=(pred==label).sum()\n",
    "        accuracy=(pred==label).float().mean()\n",
    "        running_acc +=num_correct.data[0]\n",
    "        #backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if i % 300 == 0:\n",
    "            print('[{}/{}] Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "                epoch + 1, num_epoches, running_loss / (batch_size * i),\n",
    "                running_acc / (batch_size * i)))\n",
    "    print('Finish {} epoch, Loss: {:.6f}, Acc: {:.6f}'.format(\n",
    "        epoch + 1, running_loss / (len(train_dataset)), running_acc / (len(\n",
    "            train_dataset))))\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "\n",
    "        img = Variable(img, volatile=True).cuda()\n",
    "        label = Variable(label, volatile=True).cuda()\n",
    "\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.data[0] * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.data[0]\n",
    "    print('Test Loss: {:.6f}, Acc: {:.6f}'.format(eval_loss / (len(\n",
    "        test_dataset)), eval_acc / (len(test_dataset))))\n",
    "    print()\n",
    "\n",
    "# savemodel\n",
    "torch.save(model.state_dict(), './cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs/anaconda3/lib/python3.6/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type CNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, './cnn_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.load('./cnn_net.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from numpy import eye                                                            \n",
    "arr = (eye(200)*255).astype('uint8') # sample array\n",
    "im = Image.fromarray(arr) # monochromatic image\n",
    "imrgb = Image.merge('RGB', (im,im,im)) # color image\n",
    "imrgb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.01176471,  0.07058824,  0.07058824,\n",
       "          0.07058824,  0.49411765,  0.53333336,  0.68627453,  0.10196079,\n",
       "          0.65098041,  1.        ,  0.96862745,  0.49803922,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.11764706,  0.14117648,\n",
       "          0.36862746,  0.60392159,  0.66666669,  0.99215686,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.88235295,  0.67450982,\n",
       "          0.99215686,  0.94901961,  0.7647059 ,  0.25098041,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.19215687,  0.93333334,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.98431373,  0.36470589,  0.32156864,\n",
       "          0.32156864,  0.21960784,  0.15294118,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.07058824,  0.85882354,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.99215686,  0.7764706 ,\n",
       "          0.71372551,  0.96862745,  0.94509804,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.3137255 ,  0.61176473,\n",
       "          0.41960785,  0.99215686,  0.99215686,  0.80392158,  0.04313726,\n",
       "          0.        ,  0.16862746,  0.60392159,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.05490196,\n",
       "          0.00392157,  0.60392159,  0.99215686,  0.35294119,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.54509807,  0.99215686,  0.74509805,  0.00784314,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.04313726,  0.74509805,  0.99215686,  0.27450982,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.13725491,  0.94509804,  0.88235295,\n",
       "          0.627451  ,  0.42352942,  0.00392157,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.31764707,  0.94117647,\n",
       "          0.99215686,  0.99215686,  0.46666667,  0.09803922,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.17647059,\n",
       "          0.72941178,  0.99215686,  0.99215686,  0.58823532,  0.10588235,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.0627451 ,  0.36470589,  0.98823529,  0.99215686,  0.73333335,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.97647059,  0.99215686,  0.97647059,\n",
       "          0.25098041,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.18039216,\n",
       "          0.50980395,  0.71764708,  0.99215686,  0.99215686,  0.81176472,\n",
       "          0.00784314,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.15294118,  0.58039218,  0.89803922,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.98039216,  0.71372551,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.09411765,  0.44705883,  0.86666667,  0.99215686,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.78823531,  0.30588236,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.09019608,  0.25882354,\n",
       "          0.83529413,  0.99215686,  0.99215686,  0.99215686,  0.99215686,\n",
       "          0.7764706 ,  0.31764707,  0.00784314,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.07058824,  0.67058825,  0.85882354,  0.99215686,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.7647059 ,  0.3137255 ,\n",
       "          0.03529412,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.21568628,\n",
       "          0.67450982,  0.88627452,  0.99215686,  0.99215686,  0.99215686,\n",
       "          0.99215686,  0.95686275,  0.52156866,  0.04313726,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.53333336,\n",
       "          0.99215686,  0.99215686,  0.99215686,  0.83137256,  0.52941179,\n",
       "          0.51764709,  0.0627451 ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from IPython.display import Image \n",
    "\n",
    "import IPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img, label = train_dataset[9119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img=img.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2d902147b8>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIrwA0n9HWTX0CnF3wXOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d8fd5bb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(img[0],cmap='Greys_r'\n",
    "      )\n",
    "# plt.imshow('lena_1', cmap='Greys_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=img.reshape((1,1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgt=torch.from_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgt = Variable(imgt).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=model(imgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro,pred=torch.max(output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 6.9332\n",
       "[torch.cuda.FloatTensor of size 1 (GPU 0)]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()    # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images).cuda()\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu() == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "     ⋮ \n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "     ⋮ \n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "...   \n",
       "     ⋮ \n",
       "\n",
       "(13,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "     ⋮ \n",
       "\n",
       "(14,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "     ⋮ \n",
       "\n",
       "(15,0 ,.,.) = \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "           ...             ⋱             ...          \n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
       "[torch.cuda.FloatTensor of size 16x1x28x28 (GPU 0)]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
